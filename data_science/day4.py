# ============================================
# Day 4 ‚Äì Exploratory Data Analysis (EDA)
# ============================================
# EDA = Understanding your dataset deeply before modeling
# Goal: Identify patterns, clean data, detect anomalies, & visualize relationships

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------------------------------
# 1Ô∏è‚É£ Load Dataset
# -----------------------------------------------------
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)

# Quick Overview
print("üîπ Basic Info:")
print(df.info())
# ‚û§ Output shows number of non-null entries, data types, and column names.

print("\nüîπ Summary Statistics:")
print(df.describe())
# ‚û§ Helps check data ranges, missing values, and possible outliers.

# -----------------------------------------------------
# 2Ô∏è‚É£ Handle Missing Values
# -----------------------------------------------------
# Fill missing Age with median (less affected by outliers)
df["Age"] = df["Age"].fillna(df["Age"].median())

# Fill missing Embarked with mode (most common value)
df["Embarked"] = df["Embarked"].fillna(df["Embarked"].mode()[0])

print("\n‚úÖ Missing values handled successfully!")
print(df.isnull().sum())
# ‚û§ Output: All columns should now have 0 missing values.

# -----------------------------------------------------
# 3Ô∏è‚É£ Remove Duplicates
# -----------------------------------------------------
before = df.shape[0]
df = df.drop_duplicates()
after = df.shape[0]
print(f"\nüßπ Removed {before - after} duplicate rows.")
# ‚û§ Ensures clean data for unbiased analysis.

# -----------------------------------------------------
# 4Ô∏è‚É£ Filter Data Example
# -----------------------------------------------------
first_class = df[df["Pclass"] == 1]
print("\nüé© First Class Passengers:")
print(first_class.head())
# ‚û§ Shows only passengers from Class 1.

# -----------------------------------------------------
# 5Ô∏è‚É£ Survival Rate by Class (Bar Chart)
# -----------------------------------------------------
survival_by_class = df.groupby("Pclass")["Survived"].mean()
print("\nüö¢ Survival Rate by Class:")
print(survival_by_class)
# ‚û§ Output Example:
# Pclass
# 1    0.629630
# 2    0.472826
# 3    0.242363

survival_by_class.plot(kind="bar", color="skyblue")
plt.title("Survival Rate by Class")
plt.ylabel("Survival Rate")
plt.xlabel("Passenger Class")
plt.show()
# ‚û§ Visualization Tip:
#     - Class 1 passengers had higher survival chance.
#     - Indicates socioeconomic influence.

# -----------------------------------------------------
# 6Ô∏è‚É£ Age Distribution (Histogram)
# -----------------------------------------------------
sns.histplot(df["Age"], kde=True, bins=20, color="purple")
plt.title("Age Distribution of Passengers")
plt.xlabel("Age")
plt.ylabel("Frequency")
plt.show()
# ‚û§ Interpretation:
#     - KDE curve shows density (probability).
#     - Helps spot if data is skewed or multimodal.

# -----------------------------------------------------
# 7Ô∏è‚É£ Age vs Fare Relationship (Scatter Plot)
# -----------------------------------------------------
plt.scatter(df["Age"], df["Fare"], alpha=0.6, color="green")
plt.title("Age vs Fare")
plt.xlabel("Age")
plt.ylabel("Fare")
plt.show()
# ‚û§ Output:
#     - Each point = passenger
#     - Older passengers tend to have higher fares (maybe 1st class bias)

# -----------------------------------------------------
# 8Ô∏è‚É£ Correlation Heatmap
# -----------------------------------------------------
numeric_df = df.select_dtypes(include=["number"])
corr = numeric_df.corr()
print("\nüìä Correlation Matrix:")
print(corr)

sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap of Titanic Dataset")
plt.show()
# ‚û§ Insights:
#     - Check strong correlations (Fare ‚Üî Pclass, Age ‚Üî SibSp, etc.)
#     - Helps feature selection in ML.

# -----------------------------------------------------
# ‚úÖ Summary Tip:
# -----------------------------------------------------
# ‚û§ EDA Steps to Remember (Interview Tip):
#     1. df.info() + df.describe() ‚Üí quick scan
#     2. Handle NaN & Duplicates
#     3. Group, Filter, Aggregate
#     4. Visualize distributions (hist/box)
#     5. Find correlations (heatmap, pairplot)
#     6. Document insights before modeling
