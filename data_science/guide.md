# ğŸ§  Data Science Practical Guide â€“ From Data to Insights

*A complete hands-on workbook for learning, practicing, and revising data analysis in Python.*

---

## ğŸŒ 1. Foundations of Data Science

### ğŸ”¹ What Is Data Science?

Data Science is the process of extracting **insights and knowledge** from data using:

* **Math & Statistics**
* **Programming (mainly Python)**
* **Domain Understanding**
* **Data Visualization & Communication**

**Goal:** Convert raw data â†’ information â†’ insights â†’ decisions.

### ğŸ”¹ Typical Workflow

1. **Define Problem** â†’ What question are we solving?
2. **Collect Data** â†’ CSVs, APIs, databases, sensors.
3. **Clean Data** â†’ Handle missing, duplicates, outliers.
4. **Explore (EDA)** â†’ Summaries, visualizations, relationships.
5. **Model** â†’ Regression, classification, clustering, etc.
6. **Interpret & Communicate** â†’ Insights, visuals, reports.

> ğŸ’¡ Tip: In most real-world cases, **80% of your time** goes into data cleaning and EDA, not modeling!

---

## âš™ï¸ 2. NumPy â€“ Numerical Computing

### ğŸ”¹ Why NumPy?

NumPy provides high-speed mathematical operations and memory-efficient arrays.

```python
import numpy as np

# Creating arrays
a = np.array([1, 2, 3])
b = np.arange(4, 7)

print(a + b)  # Output: [5 7 9]
print(a * 2)  # Output: [2 4 6]
```

### ğŸ”¹ Key Operations

```python
matrix = np.array([[1, 2], [3, 4]])
print(matrix.T)         # Transpose
print(np.mean(matrix))  # Average value
print(np.std(matrix))   # Standard deviation
```

### ğŸ”¹ Broadcasting

Allows operations between arrays of **different shapes**.

```python
m = np.array([[1, 2, 3], [4, 5, 6]])
v = np.array([1, 0, -1])
print(m + v)
# Output:
# [[2 2 2]
#  [5 5 5]]
```

> ğŸ§© **Use Tip:** NumPy is ideal for mathematical computing before data enters Pandas.

---

## ğŸ§¾ 3. Pandas â€“ Data Manipulation & Cleaning

### ğŸ”¹ Data Structures

* **Series:** 1D labeled array
* **DataFrame:** 2D labeled table (rows & columns)

```python
import pandas as pd

data = {"Name": ["Alice", "Bob"], "Age": [25, 30]}
df = pd.DataFrame(data)
print(df)
# Output:
#     Name  Age
# 0  Alice   25
# 1    Bob   30
```

### ğŸ”¹ Reading / Writing Data

```python
df = pd.read_csv("data.csv")   # Read
df.to_csv("output.csv", index=False)  # Write
```

### ğŸ”¹ Cleaning & Handling Missing Data

```python
df["Age"].fillna(df["Age"].mean(), inplace=True)
df.drop_duplicates(inplace=True)
```

### ğŸ”¹ Filtering, Sorting, Aggregating

```python
print(df[df["Age"] > 25])
df.sort_values(by="Age", inplace=True)
df.groupby("Department")["Salary"].mean()
```

> ğŸ’¡ **Use Tip:**
>
> * Pandas = Data wrangling powerhouse.
> * Combine with NumPy for numerical operations.

---

## ğŸ“Š 4. Data Visualization â€“ Matplotlib & Seaborn

### ğŸ”¹ Matplotlib Basics

```python
import matplotlib.pyplot as plt

x = [1, 2, 3, 4]
y = [10, 20, 25, 30]
plt.plot(x, y, color="blue", marker="o")
plt.title("Sales Trend")
plt.xlabel("Year")
plt.ylabel("Sales")
plt.show()
```

### ğŸ”¹ Seaborn â€“ High-level Visualization

```python
import seaborn as sns
import pandas as pd

df = pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv")

sns.histplot(df["sepal_length"], kde=True, color="purple")
plt.title("Sepal Length Distribution")
plt.show()
```

### ğŸ”¹ Correlation Heatmap

```python
corr = df.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.title("Feature Correlations")
plt.show()
```

> ğŸ¨ **Use Tip:**
>
> * **Matplotlib** â†’ Full control & customization
> * **Seaborn** â†’ Cleaner, faster, statistical plots

---

## ğŸ” 5. EDA (Exploratory Data Analysis)

### ğŸ”¹ Step-by-Step EDA Process

1. **Understand the dataset**

   ```python
   print(df.info())
   print(df.describe())
   print(df.isnull().sum())
   ```

2. **Handle missing/outliers**

   ```python
   df["Age"].fillna(df["Age"].median(), inplace=True)
   df = df[df["Fare"] < 500]  # remove outliers
   ```

3. **Explore relationships**

   ```python
   sns.boxplot(x="Pclass", y="Age", data=df)
   sns.countplot(x="Survived", data=df)
   ```

4. **Visual Summary**

   ```python
   sns.pairplot(df, hue="Survived")
   plt.show()
   ```

> ğŸ§  **Goal:** Reveal trends, correlations, and anomalies before modeling.

---

## ğŸ“ˆ 6. From EDA to Insights

### ğŸ”¹ Aggregation

```python
summary = df.groupby("Pclass")["Fare"].agg(["mean", "max", "min"])
print(summary)
```

### ğŸ”¹ Feature Relationships

* Use **pairplot** for numeric relations
* Use **barplot** or **countplot** for categorical relations

### ğŸ”¹ Communication

End every analysis with:

* Key findings (insights)
* Supporting visual evidence
* Business interpretation


